{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import GetOldTweets3 as got\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The function itself\n",
    "\n",
    "I'll probably nest this in a functions.py file in the final project so it doesn't take up notebook space, but leaving it here for now so you can look through it easily, if you'd like! Scroll to the bottom to use it :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_tweets_to_csv(query:str, max_tweets:int, cities:dict, date_range:tuple, state:str, sleep_time:float=1.5):\n",
    "    '''\n",
    "    A function for returning search results on a query\n",
    "    to create a representative sample of a state/region\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    query : string, a search query to be passed through\n",
    "    Twitter's advanced search. Can use booleans within\n",
    "    the query!\n",
    "    \n",
    "    max_tweets : int, number of tweets to pull, recommend\n",
    "    staying within the boundaries of the twitter API limitations\n",
    "    (recommend using 18000 as an upper limit)\n",
    "    \n",
    "    cities : dict, dictionary where the keys are [city, state abbreviation] \n",
    "    and the values are the distance around the city to search.\n",
    "    Keys should be strings, values can be strings or integers.\n",
    "    Not case-sensitive\n",
    "    Example: {'chicago': 10, 'sPringfield': '20'}\n",
    "    \n",
    "    date_range : tuple, a range of dates as stringts to pull \n",
    "    tweets from, formatted as 'YYYY-MM-DD'. Put earliest date first. \n",
    "    Example: ('2020-03-20', '2020-03-25')\n",
    "    \n",
    "    state : string, enter the two-letter state code you are pulling info from.\n",
    "    Not case-sensitive.\n",
    "    '''\n",
    "    def csv_store(resultsAux):\n",
    "        '''\n",
    "        A function that is used within getTweets() as a receive buffer.\n",
    "        This function stores a city's info in a .csv so if you hit a\n",
    "        rate limit, your data gets saved.\n",
    "        '''\n",
    "        # Create dataframe from the temporary variable, resultsAux (comes from getTweets() source code)\n",
    "        df = pd.DataFrame(t.__dict__ for t in resultsAux)\n",
    "        \n",
    "        # Add city column to this df and write to new .csv, the .csv will be removed at the end of the whole function\n",
    "        df['city'] = city\n",
    "        df['query'] = query\n",
    "        df['date_range'] = str(date_range)\n",
    "        df.to_csv(f'./data/{city}_scrape_data.csv', index=False, mode='a')\n",
    "        \n",
    "    \n",
    "    # Create a static timestamp to use for versioning\n",
    "    timestamp = str(time.ctime().replace(' ', '_').replace(':', '_'))\n",
    "    \n",
    "    # Set state to uppercase for filenaming uniformity\n",
    "    state = state.upper()\n",
    "    \n",
    "    for city, area in cities.items():\n",
    "        # Make city lowercase for consitent file naming\n",
    "        city = city.lower()\n",
    "        \n",
    "        # Try to get all tweets as determined by max_tweets\n",
    "        try:\n",
    "            tweetCriteria = got.manager.TweetCriteria().setQuerySearch(query)\\\n",
    "                                               .setSince(date_range[0])\\\n",
    "                                               .setUntil(date_range[1])\\\n",
    "                                               .setMaxTweets(max_tweets)\\\n",
    "                                               .setNear(f'{city}, {state}')\\\n",
    "                                               .setWithin(f'{str(area)}mi')\n",
    "            tweets = got.manager.TweetManager.getTweets(tweetCriteria, \n",
    "                                                        receiveBuffer=csv_store) # This receive buffer goes into the csv_store function defined above\n",
    "\n",
    "            # Let's get the current city's csv that was created above\n",
    "            current_city = pd.read_csv(f'./data/{city}_scrape_data.csv')\n",
    "            \n",
    "            # Tell me how many tweets we collected\n",
    "            print(f'Finished collecting tweets from {city}, we got {len(current_city)} tweets')\n",
    "\n",
    "            # Is this the first city?\n",
    "            if city == list(cities.keys())[0]:\n",
    "                # Create a .csv and put each city's data inside\n",
    "                current_city.to_csv(f'./data/{state}_scrape_data_{timestamp}.csv', mode='a', index=False)\n",
    "                # Clean up the directory by removing the city's .csv\n",
    "                os.remove(f'./data/{city}_scrape_data.csv')\n",
    "            \n",
    "            else:\n",
    "                # Don't need header for anything but the first city\n",
    "                current_city.to_csv(f'./data/{state}_scrape_data_{timestamp}.csv', mode='a', index=False, header=False)\n",
    "                os.remove(f'./data/{city}_scrape_data.csv')\n",
    "                \n",
    "            # Rest a random amount to try not to be detected as a bot\n",
    "            time.sleep(np.random.normal(sleep_time, 0.1))\n",
    "        \n",
    "        # If one of the searches didn't return anything, it won't create a .csv and will throw an error, let's account for that\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "        \n",
    "        # This is just a general catch-all for any other issues (including timeouts)\n",
    "        except:\n",
    "        \n",
    "            # If there were errors above, we'll have to account for the missing .csvs with another try/except\n",
    "            try:\n",
    "                # Let's get the current city's csv that was created above\n",
    "                current_city = pd.read_csv(f'./data/{city}_scrape_data.csv')\n",
    "\n",
    "                # Tell me how many tweets we collected\n",
    "                print(f'Finished collecting tweets from {city}, we got {len(current_city)} tweets')\n",
    "\n",
    "                # Is this the first city?\n",
    "                if city == list(cities.keys())[0]:\n",
    "                    # Create a .csv and put each city's data inside\n",
    "                    current_city.to_csv(f'./data/{state}_scrape_data_{timestamp}.csv', mode='a', index=False)\n",
    "                    # Clean up the directory by removing the city's .csv\n",
    "                    os.remove(f'./data/{city}_scrape_data.csv')\n",
    "\n",
    "                else:\n",
    "                    # Don't need header for anything but the first city\n",
    "                    current_city.to_csv(f'./data/{state}_scrape_data_{timestamp}.csv', mode='a', index=False, header=False)\n",
    "                    os.remove(f'./data/{city}_scrape_data.csv')\n",
    "\n",
    "                    # Rest a random amount to try not to be detected as a bot\n",
    "                    time.sleep(np.random.normal(sleep_time, 0.1))\n",
    "            \n",
    "            # If the .csv didn't exist, just sleep and go on to the next city!\n",
    "            except:\n",
    "                time.sleep(np.random.normal(sleep_time, 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use this area to collect tweets!\n",
    "\n",
    "I haven't been able to grab many tweets from rural areas in a short date range, thinking about expanding date range before and after an announcement so that non-urban areas are better represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'covid OR COVID-19 OR covid19 OR murphy OR corona OR coronavirus OR gov OR governor OR capital'\n",
    "max_tweets = 1000\n",
    "\n",
    "# Picking wider ranges for more rural areas, shallower ranges for cities, used google maps to try not to overlap, but we can also check for duplicates afterward.\n",
    "cities = {\n",
    "          'newark': 10,\n",
    "          'trenton': 5,\n",
    "          'camden': 20,\n",
    "          'jersey city': 10,\n",
    "          'vineland': 30,\n",
    "          'Hoboken': 20,\n",
    "          'passaic': 20,\n",
    "          'clifton': 20,\n",
    "          'bayonne': 10,\n",
    "          'elizabeth': 10,\n",
    "          'paterson': 20\n",
    "         }\n",
    "date_range = ('2020-03-07', '2020-03-15')\n",
    "state = 'nj'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished collecting tweets from newark, we got 1009 tweets\n",
      "Finished collecting tweets from trenton, we got 670 tweets\n",
      "Finished collecting tweets from camden, we got 1009 tweets\n",
      "Finished collecting tweets from jersey city, we got 1009 tweets\n",
      "Finished collecting tweets from vineland, we got 49 tweets\n",
      "Finished collecting tweets from hoboken, we got 1009 tweets\n",
      "Finished collecting tweets from passaic, we got 1009 tweets\n",
      "Finished collecting tweets from clifton, we got 1009 tweets\n",
      "Finished collecting tweets from bayonne, we got 1009 tweets\n",
      "Finished collecting tweets from elizabeth, we got 1009 tweets\n",
      "Finished collecting tweets from paterson, we got 1009 tweets\n"
     ]
    }
   ],
   "source": [
    "state_tweets_to_csv(query, max_tweets, cities, date_range, state, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>to</th>\n",
       "      <th>text</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>replies</th>\n",
       "      <th>id</th>\n",
       "      <th>permalink</th>\n",
       "      <th>author_id</th>\n",
       "      <th>date</th>\n",
       "      <th>formatted_date</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>geo</th>\n",
       "      <th>urls</th>\n",
       "      <th>city</th>\n",
       "      <th>query</th>\n",
       "      <th>date_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>marigreyes13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jeeee y confirmaron el primer caso de coronavi...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1238977968237674497</td>\n",
       "      <td>https://twitter.com/marigreyes13/status/123897...</td>\n",
       "      <td>49742903</td>\n",
       "      <td>2020-03-14 23:59:01+00:00</td>\n",
       "      <td>Sat Mar 14 23:59:01 +0000 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>newark</td>\n",
       "      <td>covid OR COVID-19 OR covid19 OR murphy OR coro...</td>\n",
       "      <td>('2020-03-07', '2020-03-15')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the_sole_broker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Travis Scott Jordan 6 GS New Size 4Y $399.99 T...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1238977927842275334</td>\n",
       "      <td>https://twitter.com/the_sole_broker/status/123...</td>\n",
       "      <td>789883607389175808</td>\n",
       "      <td>2020-03-14 23:58:51+00:00</td>\n",
       "      <td>Sat Mar 14 23:58:51 +0000 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.instagram.com/p/B9u7yfAp_-z/?igshi...</td>\n",
       "      <td>newark</td>\n",
       "      <td>covid OR COVID-19 OR covid19 OR murphy OR coro...</td>\n",
       "      <td>('2020-03-07', '2020-03-15')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baskarbhat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Indian way to avoid contact of hands! Help spr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1238977889783156736</td>\n",
       "      <td>https://twitter.com/Baskarbhat/status/12389778...</td>\n",
       "      <td>47604483</td>\n",
       "      <td>2020-03-14 23:58:42+00:00</td>\n",
       "      <td>Sat Mar 14 23:58:42 +0000 2020</td>\n",
       "      <td>#COVID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>newark</td>\n",
       "      <td>covid OR COVID-19 OR covid19 OR murphy OR coro...</td>\n",
       "      <td>('2020-03-07', '2020-03-15')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MatthewDrutt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trumps tests negative for COVID-19. Anybody te...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1238977746627440643</td>\n",
       "      <td>https://twitter.com/MatthewDrutt/status/123897...</td>\n",
       "      <td>152975295</td>\n",
       "      <td>2020-03-14 23:58:08+00:00</td>\n",
       "      <td>Sat Mar 14 23:58:08 +0000 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>newark</td>\n",
       "      <td>covid OR COVID-19 OR covid19 OR murphy OR coro...</td>\n",
       "      <td>('2020-03-07', '2020-03-15')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MaineventL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Get ready for war #covid #coronavirüsü http://...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1238977728105320448</td>\n",
       "      <td>https://twitter.com/MaineventL/status/12389777...</td>\n",
       "      <td>1140542122065649664</td>\n",
       "      <td>2020-03-14 23:58:04+00:00</td>\n",
       "      <td>Sat Mar 14 23:58:04 +0000 2020</td>\n",
       "      <td>#covid #coronavir #facemask #camo #faceshield ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://Maineventlingerie.com,https://www.insta...</td>\n",
       "      <td>newark</td>\n",
       "      <td>covid OR COVID-19 OR covid19 OR murphy OR coro...</td>\n",
       "      <td>('2020-03-07', '2020-03-15')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username   to                                               text  \\\n",
       "0     marigreyes13  NaN  Jeeee y confirmaron el primer caso de coronavi...   \n",
       "1  the_sole_broker  NaN  Travis Scott Jordan 6 GS New Size 4Y $399.99 T...   \n",
       "2       Baskarbhat  NaN  Indian way to avoid contact of hands! Help spr...   \n",
       "3     MatthewDrutt  NaN  Trumps tests negative for COVID-19. Anybody te...   \n",
       "4       MaineventL  NaN  Get ready for war #covid #coronavirüsü http://...   \n",
       "\n",
       "  retweets favorites replies                   id  \\\n",
       "0        0         2       1  1238977968237674497   \n",
       "1        0         0       0  1238977927842275334   \n",
       "2        0         0       0  1238977889783156736   \n",
       "3        0         1       0  1238977746627440643   \n",
       "4        0         0       0  1238977728105320448   \n",
       "\n",
       "                                           permalink            author_id  \\\n",
       "0  https://twitter.com/marigreyes13/status/123897...             49742903   \n",
       "1  https://twitter.com/the_sole_broker/status/123...   789883607389175808   \n",
       "2  https://twitter.com/Baskarbhat/status/12389778...             47604483   \n",
       "3  https://twitter.com/MatthewDrutt/status/123897...            152975295   \n",
       "4  https://twitter.com/MaineventL/status/12389777...  1140542122065649664   \n",
       "\n",
       "                        date                  formatted_date  \\\n",
       "0  2020-03-14 23:59:01+00:00  Sat Mar 14 23:59:01 +0000 2020   \n",
       "1  2020-03-14 23:58:51+00:00  Sat Mar 14 23:58:51 +0000 2020   \n",
       "2  2020-03-14 23:58:42+00:00  Sat Mar 14 23:58:42 +0000 2020   \n",
       "3  2020-03-14 23:58:08+00:00  Sat Mar 14 23:58:08 +0000 2020   \n",
       "4  2020-03-14 23:58:04+00:00  Sat Mar 14 23:58:04 +0000 2020   \n",
       "\n",
       "                                            hashtags mentions  geo  \\\n",
       "0                                                NaN      NaN  NaN   \n",
       "1                                                NaN      NaN  NaN   \n",
       "2                                             #COVID      NaN  NaN   \n",
       "3                                                NaN      NaN  NaN   \n",
       "4  #covid #coronavir #facemask #camo #faceshield ...      NaN  NaN   \n",
       "\n",
       "                                                urls    city  \\\n",
       "0                                                NaN  newark   \n",
       "1  https://www.instagram.com/p/B9u7yfAp_-z/?igshi...  newark   \n",
       "2                                                NaN  newark   \n",
       "3                                                NaN  newark   \n",
       "4  http://Maineventlingerie.com,https://www.insta...  newark   \n",
       "\n",
       "                                               query  \\\n",
       "0  covid OR COVID-19 OR covid19 OR murphy OR coro...   \n",
       "1  covid OR COVID-19 OR covid19 OR murphy OR coro...   \n",
       "2  covid OR COVID-19 OR covid19 OR murphy OR coro...   \n",
       "3  covid OR COVID-19 OR covid19 OR murphy OR coro...   \n",
       "4  covid OR COVID-19 OR covid19 OR murphy OR coro...   \n",
       "\n",
       "                     date_range  \n",
       "0  ('2020-03-07', '2020-03-15')  \n",
       "1  ('2020-03-07', '2020-03-15')  \n",
       "2  ('2020-03-07', '2020-03-15')  \n",
       "3  ('2020-03-07', '2020-03-15')  \n",
       "4  ('2020-03-07', '2020-03-15')  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nj = pd.read_csv('./data/NJ_scrape_data_Thu_Sep_10_16_51_42_2020.csv')\n",
    "nj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9800 entries, 0 to 9799\n",
      "Data columns (total 18 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   username        9800 non-null   object\n",
      " 1   to              2217 non-null   object\n",
      " 2   text            9799 non-null   object\n",
      " 3   retweets        9800 non-null   object\n",
      " 4   favorites       9800 non-null   object\n",
      " 5   replies         9800 non-null   object\n",
      " 6   id              9800 non-null   object\n",
      " 7   permalink       9800 non-null   object\n",
      " 8   author_id       9800 non-null   object\n",
      " 9   date            9800 non-null   object\n",
      " 10  formatted_date  9800 non-null   object\n",
      " 11  hashtags        4786 non-null   object\n",
      " 12  mentions        2291 non-null   object\n",
      " 13  geo             87 non-null     object\n",
      " 14  urls            3476 non-null   object\n",
      " 15  city            9800 non-null   object\n",
      " 16  query           9800 non-null   object\n",
      " 17  date_range      9800 non-null   object\n",
      "dtypes: object(18)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "nj.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
